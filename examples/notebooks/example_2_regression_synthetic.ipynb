{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 2: Regression with Synthetic data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "if not Path(\"datasets\").exists():\n",
    "    os.mkdir(\"datasets\")\n",
    "if not Path(\"results\").exists():\n",
    "    os.mkdir(\"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell is generating some synthetic graph dataset with node features.\n",
    "\n",
    "\n",
    "# defining limits on number of nodes\n",
    "n_min = 20\n",
    "n_max = 50\n",
    "\n",
    "# number of graphs\n",
    "num_g = 50\n",
    "\n",
    "# number of node features - in this example I will generate random node features that aren't useful for classifcation\n",
    "n_nf = 3\n",
    "\n",
    "\n",
    "# empty list of graphs and labels\n",
    "graphs = []\n",
    "labels = []\n",
    "node_features = []\n",
    "\n",
    "\n",
    "# setting limits on probability of edge existing for random graphs\n",
    "p_min = 0.05\n",
    "p_max = 0.9\n",
    "\n",
    "# adding 50 random graphs and adding the label corresponding to probability of edge existing\n",
    "for i in range(num_g):\n",
    "    rand_n = np.random.randint(n_min, n_max)\n",
    "    rand_p = np.random.randint(int(p_min * 100), int(p_max * 100)) / 100\n",
    "\n",
    "    g = nx.fast_gnp_random_graph(rand_n, rand_p)\n",
    "    node_feat_matrix = np.random.random((rand_n, n_nf))\n",
    "\n",
    "    graphs.append(nx.to_numpy_array(g))\n",
    "    node_features.append(node_feat_matrix)\n",
    "\n",
    "    labels.append(rand_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting this data into the format required for hcga\n",
    "\n",
    "from hcga.graph import Graph, GraphCollection\n",
    "\n",
    "# create graph collection object\n",
    "g_c = GraphCollection()\n",
    "\n",
    "# add graphs, node features and labels to the object\n",
    "g_c.add_graph_list(graphs, node_features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform some sanity checks\n",
    "\n",
    "print(\"There are {} graphs\".format(len(g_c.graphs)))\n",
    "print(\"There are {} features per node\".format(g_c.get_n_node_features()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can save this if we want to and run everything from the command line\n",
    "from hcga.io import save_dataset\n",
    "\n",
    "save_dataset(\n",
    "    g_c, \"custom_dataset_regression\", folder=\"./datasets/custom_dataset_regression\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting features\n",
    "\n",
    "We have now produced a pickle dataset of your own custom data. We can now run the feature extraction from the command line using the following commands:\n",
    "\n",
    "hcga extract_features ./datasets/custom_dataset.pkl -m fast -n 4 -sl advanced --timeout 10 \n",
    "\n",
    "\n",
    "Alternatively,we could import the Hcga class and run the feature extraction and analysis from within the notebook. We will do this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hcga.io import load_dataset\n",
    "\n",
    "graphs = load_dataset(\n",
    "    \"./datasets/custom_dataset_regression/custom_dataset_regression.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hcga object\n",
    "from hcga.hcga import Hcga\n",
    "\n",
    "# define an object\n",
    "h = Hcga()\n",
    "\n",
    "# assigning the graphs field to the recently created dataset\n",
    "h.graphs = graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extracting all features here\n",
    "h.extract(mode=\"fast\", n_workers=4, timeout=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving all features into a pickle\n",
    "h.save_features(\"./results/custom_dataset_regression/all_features.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved features\n",
    "\n",
    "h.load_features(\"./results/custom_dataset_regression/all_features.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement a classification analyse of the features\n",
    "h.analyse_features(\n",
    "    feature_file=\"./results/custom_dataset_regression/all_features.pkl\",\n",
    "    analysis_type=\"regression\",\n",
    "    results_folder=\"./results/custom_dataset_regression\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
