{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 5: Exploring the similarity between classes\n",
    "\n",
    "Here, we provide an example in which we construct three classes of graphs. We then compare each class pairwise to identify which classes are similar to each other. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "if not Path(\"datasets\").exists():\n",
    "    os.mkdir(\"datasets\")\n",
    "if not Path(\"results\").exists():\n",
    "    os.mkdir(\"results\")\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters for constructing synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining limits on number of nodes\n",
    "n_min = 20\n",
    "n_max = 50\n",
    "\n",
    "# number of graphs\n",
    "num_g = 50\n",
    "\n",
    "# number of node features - in this example I will generate random node features that aren't useful for classifcation\n",
    "n_nf = 3\n",
    "\n",
    "# empty list of graphs and labels\n",
    "graphs = []\n",
    "labels = []\n",
    "node_features = []\n",
    "\n",
    "# setting limits on probability of edge existing for random graphs\n",
    "p_min = 0.1\n",
    "p_max = 0.5\n",
    "\n",
    "# setting limits on number of edges to add per node\n",
    "m_min = 3\n",
    "m_max = 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data for class 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding 50 random graphs (label 0)\n",
    "for i in range(num_g):\n",
    "    rand_n = np.random.randint(n_min, n_max)\n",
    "    rand_p = np.random.randint(int(p_min * 100), int(p_max * 100)) / 100\n",
    "\n",
    "    g = nx.fast_gnp_random_graph(rand_n, rand_p)\n",
    "    node_feat_matrix = np.random.random((rand_n, n_nf))\n",
    "\n",
    "    graphs.append(g)\n",
    "    node_features.append(node_feat_matrix)\n",
    "\n",
    "    labels.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data for class 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding 50  powerlaw cluster graphs (label 1)\n",
    "for i in range(num_g):\n",
    "    rand_n = np.random.randint(n_min, n_max)\n",
    "    rand_p = np.random.randint(int(p_min * 100), int(p_max * 100)) / 100\n",
    "    rand_m = np.random.randint(m_min, m_max)\n",
    "\n",
    "    g = nx.powerlaw_cluster_graph(rand_n, rand_m, rand_p)\n",
    "    node_feat_matrix = np.random.random((rand_n, n_nf))\n",
    "\n",
    "    graphs.append(g)\n",
    "    node_features.append(node_feat_matrix)\n",
    "\n",
    "    labels.append(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create data for class 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding 50 watts strogatz graphs (label 2)\n",
    "for i in range(num_g):\n",
    "    rand_n = np.random.randint(n_min, n_max)\n",
    "    rand_p = np.random.randint(int(p_min * 100), int(p_max * 100)) / 100\n",
    "    rand_m = np.random.randint(m_min, m_max)\n",
    "\n",
    "    g = nx.watts_strogatz_graph(rand_n, rand_m, rand_p)\n",
    "    node_feat_matrix = np.random.random((rand_n, n_nf))\n",
    "\n",
    "    graphs.append(g)\n",
    "    node_features.append(node_feat_matrix)\n",
    "\n",
    "    labels.append(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load graphs into graph object\n",
    "\n",
    "We now have three lists of length 100. The graphs list is composed of numpy arrays that represent the adjacency matrix of the graph. The node features list is composed of numpy arrays that contain the node information for each graph. The labels list is a list of integers that corresponds to the class label for each graph.\n",
    "\n",
    "The next step is to take this data and convert it into an appropriate format for hcga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting this data into the format required for hcga\n",
    "\n",
    "from hcga.graph import Graph, GraphCollection\n",
    "\n",
    "# create graph collection object\n",
    "g_c = GraphCollection()\n",
    "\n",
    "# add graphs, node features and labels to the object\n",
    "g_c.add_graph_list(graphs, node_features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform some sanity checks\n",
    "\n",
    "print(\"There are {} graphs\".format(len(g_c.graphs)))\n",
    "print(\"There are {} features per node\".format(g_c.get_n_node_features()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can save this if we want to and run everything from the command line\n",
    "from hcga.io import save_dataset\n",
    "\n",
    "save_dataset(\n",
    "    g_c,\n",
    "    \"custom_dataset_multilabel_similarity\",\n",
    "    folder=\"./datasets/custom_multilabel_similarity\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hcga object\n",
    "from hcga.hcga import Hcga\n",
    "\n",
    "# define an object\n",
    "h = Hcga()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load previously saved dataset\n",
    "h.load_data(\n",
    "    \"./datasets/custom_multilabel_similarity/custom_dataset_multilabel_similarity.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extracting all features here\n",
    "h.extract(mode=\"fast\", n_workers=4, timeout=5)\n",
    "\n",
    "# saving all features into a pickle\n",
    "h.save_features(\"./results/custom_multilabel_similarity/all_features.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved features\n",
    "\n",
    "h.load_features(\"./results/custom_multilabel_similarity/all_features.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement a classification analyse of the features\n",
    "\n",
    "h.analyse_features(\n",
    "    feature_file=\"./results/custom_multilabel_similarity/all_features.pkl\",\n",
    "    results_folder=\"./results/custom_multilabel_similarity\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pairwise classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_matrix, top_features = h.pairwise_classification(\n",
    "    feature_file=\"./results/custom_multilabel_similarity/all_features.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(accuracy_matrix)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what are the top features for classifying between class 0 and class 1?\n",
    "print(top_features[(0.0, 1.0)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
