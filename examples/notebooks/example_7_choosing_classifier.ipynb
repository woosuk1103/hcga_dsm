{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 7: Using different classifiers\n",
    "\n",
    "hcga has been constructed so that the user can easily choose the statistical learning algorithm of their choice. By default we use the xgboost algorithm because it seamlessly integrates with the shapley values toolbox. However, users can input their own or choose from some already pre-defined algorithms. \n",
    "\n",
    "Here, we assume that you have already run example 1 and you can simply load in the features that were produced and saved.\n",
    "\n",
    "## Important!\n",
    "\n",
    "SHAPley values were first designed for Tree based algorithms. They are fast to compute for tree based algorithms.  However, Kernel based algorithms require a different Explainer function which is both slow and requires a lot of memory and computing power. I highly recommend users to not compute SHAP values when using Kernel based algorithms such as Support Vector Machines (pass the argument 'compute_shap=False' to stop this step).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "if not Path(\"datasets\").exists():\n",
    "    os.mkdir(\"datasets\")\n",
    "if not Path(\"results\").exists():\n",
    "    os.mkdir(\"results\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data from Example 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hcga.hcga import Hcga\n",
    "\n",
    "# WARNING: you need to run example_1 before this notebook\n",
    "\n",
    "h = Hcga()\n",
    "h.load_features(\"./results/custom_dataset_classification/all_features.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# first we use the default\n",
    "model = \"XG\"\n",
    "h.analyse_features(\n",
    "    model=model,\n",
    "    plot=False,\n",
    "    feature_file=\"./results/custom_dataset_classification/all_features.pkl\",\n",
    "    results_folder=\"./results/custom_dataset_classification\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the random forest classifier inbuilt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = \"RF\"\n",
    "h.analyse_features(\n",
    "    model=model,\n",
    "    plot=False,\n",
    "    feature_file=\"./results/custom_dataset_classification/all_features.pkl\",\n",
    "    results_folder=\"./results/custom_dataset_classification\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use custom Support Vector Machine classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "model = SVC(\n",
    "    probability=True\n",
    ")  # it is necessary to use probability=True to compute SHAP values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can compute with shap values\n",
    "h.analyse_features(\n",
    "    compute_shap=False,\n",
    "    model=model,\n",
    "    plot=False,\n",
    "    feature_file=\"./results/custom_dataset_classification/all_features.pkl\",\n",
    "    results_folder=\"./results/custom_dataset_classification\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or with shap values:\n",
    "# WARNING the Kernel Explainer (for general models) is slow and requires a lot of memory\n",
    "h.analyse_features(\n",
    "    compute_shap=True,\n",
    "    kfold=False,\n",
    "    model=model,\n",
    "    plot=False,\n",
    "    feature_file=\"./results/custom_dataset_classification/all_features.pkl\",\n",
    "    results_folder=\"./results/custom_dataset_classification\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "model = KNeighborsClassifier()\n",
    "h.analyse_features(\n",
    "    compute_shap=False,\n",
    "    model=model,\n",
    "    plot=False,\n",
    "    feature_file=\"./results/custom_dataset_classification/all_features.pkl\",\n",
    "    results_folder=\"./results/custom_dataset_classification\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
