{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Classification with Synthetic data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import scipy as sc\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "if not Path(\"datasets\").exists():\n",
    "    os.mkdir(\"datasets\")\n",
    "if not Path(\"results\").exists():\n",
    "    os.mkdir(\"results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(27, 27)\n"
     ]
    }
   ],
   "source": [
    "# this cell is generating some synthetic graph dataset with node features.\n",
    "\n",
    "\n",
    "# defining limits on number of nodes\n",
    "n_min = 20\n",
    "n_max = 50\n",
    "\n",
    "# number of graphs\n",
    "num_g = 1\n",
    "\n",
    "# number of node features - in this example I will generate random node features that aren't useful for classifcation\n",
    "n_nf = 3\n",
    "\n",
    "\n",
    "# empty list of graphs and labels\n",
    "graphs = []\n",
    "labels = []\n",
    "node_features = []\n",
    "\n",
    "\n",
    "# setting limits on probability of edge existing for random graphs\n",
    "p_min = 0.1\n",
    "p_max = 0.5\n",
    "\n",
    "# adding 50 random graphs (label 0)\n",
    "# for i in range(int(num_g / 2)):\n",
    "#     rand_n = np.random.randint(n_min, n_max)\n",
    "#     rand_p = np.random.randint(int(p_min * 100), int(p_max * 100)) / 100\n",
    "\n",
    "#     g = nx.fast_gnp_random_graph(rand_n, rand_p)\n",
    "#     node_feat_matrix = np.random.random((rand_n, n_nf))\n",
    "    \n",
    "#     graphs.append(nx.to_numpy_array(g))\n",
    "#     node_features.append(node_feat_matrix)\n",
    "\n",
    "#     labels.append(0)\n",
    "\n",
    "# setting limits on number of edges to add per node\n",
    "m_min = 1\n",
    "m_max = 5\n",
    "\n",
    "# adding 50 powerlaw cluster graphs (label 1)\n",
    "# for i in range(int(num_g / 2)):\n",
    "\n",
    "#     rand_n = np.random.randint(n_min, n_max)\n",
    "#     rand_p = np.random.randint(int(p_min * 100), int(p_max * 100)) / 100\n",
    "#     rand_m = np.random.randint(m_min, m_max)\n",
    "\n",
    "#     g = nx.powerlaw_cluster_graph(rand_n, rand_m, rand_p)\n",
    "#     node_feat_matrix = np.random.random((rand_n, n_nf))\n",
    "    \n",
    "#     print(type(nx.to_numpy_array(g)))\n",
    "#     if i == 3:\n",
    "#         print(type(nx.to_numpy_array(g)))\n",
    "#     graphs.append(nx.to_numpy_array(g))\n",
    "#     node_features.append(node_feat_matrix)\n",
    "\n",
    "#     labels.append(1)\n",
    "\n",
    "\n",
    "rand_n = np.random.randint(n_min, n_max)\n",
    "rand_p = np.random.randint(int(p_min * 100), int(p_max * 100)) / 100\n",
    "rand_m = np.random.randint(m_min, m_max)\n",
    "\n",
    "g = nx.powerlaw_cluster_graph(rand_n, rand_m, rand_p)\n",
    "node_feat_matrix = np.random.random((rand_n, n_nf))\n",
    "\n",
    "print(type(nx.to_numpy_array(g)))\n",
    "print(nx.to_numpy_array(g).shape)\n",
    "\n",
    "graphs.append(nx.to_numpy_array(g))\n",
    "node_features.append(node_feat_matrix)\n",
    "\n",
    "labels.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = []\n",
    "labels = []\n",
    "node_features = []\n",
    "\n",
    "# define the number of nodes\n",
    "n = 38\n",
    "\n",
    "# number of node features\n",
    "n_nf = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the dsm\n",
    "dsm = np.identity(n)\n",
    "\n",
    "dsm[0][2] = 1\n",
    "dsm[0][3] = 1\n",
    "dsm[0][7] = 1\n",
    "dsm[0][10] = 1\n",
    "dsm[0][32] = 1\n",
    "dsm[0][35] = 1\n",
    "\n",
    "dsm[1][7] = 1\n",
    "dsm[1][8] = 1\n",
    "dsm[1][32] = 1\n",
    "\n",
    "dsm[2][10] = 1\n",
    "dsm[2][13] = 1\n",
    "dsm[2][14] = 1\n",
    "dsm[2][29] = 1\n",
    "dsm[2][35] = 1\n",
    "\n",
    "dsm[3][7] = 1\n",
    "dsm[3][13] = 1\n",
    "dsm[3][29] = 1\n",
    "dsm[3][35] = 1\n",
    "\n",
    "dsm[4][5] = 1\n",
    "dsm[4][6] = 1\n",
    "dsm[4][20] = 1\n",
    "dsm[4][25] = 1\n",
    "dsm[4][36] = 1\n",
    "\n",
    "dsm[5][6] = 1\n",
    "dsm[5][20] = 1\n",
    "\n",
    "dsm[6][20] = 1\n",
    "dsm[6][22] = 1\n",
    "dsm[6][23] = 1\n",
    "dsm[6][37] = 1\n",
    "\n",
    "dsm[7][8] = 1\n",
    "dsm[7][14] = 1\n",
    "dsm[7][22] = 1\n",
    "dsm[7][23] = 1\n",
    "dsm[7][28] = 1\n",
    "dsm[7][29] = 1\n",
    "dsm[7][30] = 1\n",
    "dsm[7][31] = 1\n",
    "dsm[7][32] = 1\n",
    "dsm[7][33] = 1\n",
    "dsm[7][34] = 1\n",
    "\n",
    "dsm[8][28] = 1\n",
    "dsm[8][29] = 1\n",
    "\n",
    "dsm[9][12] = 1\n",
    "dsm[9][13] = 1\n",
    "dsm[9][18] = 1\n",
    "dsm[9][33] = 1\n",
    "dsm[9][34] = 1\n",
    "\n",
    "dsm[10][13] = 1\n",
    "dsm[10][17] = 1\n",
    "dsm[10][35] = 1\n",
    "\n",
    "dsm[11][19] = 1\n",
    "dsm[11][27] = 1\n",
    "dsm[11][36] = 1\n",
    "\n",
    "dsm[12][13] = 1\n",
    "\n",
    "dsm[13][14] = 1\n",
    "dsm[13][16] = 1\n",
    "dsm[13][17] = 1\n",
    "\n",
    "dsm[14][16] = 1\n",
    "dsm[14][18] = 1\n",
    "dsm[14][26] = 1\n",
    "dsm[14][27] = 1\n",
    "dsm[14][29] = 1\n",
    "\n",
    "dsm[15][31] = 1\n",
    "dsm[15][32] = 1\n",
    "\n",
    "dsm[16][17] = 1\n",
    "dsm[16][26] = 1\n",
    "\n",
    "dsm[17][35] = 1\n",
    "\n",
    "dsm[18][19] = 1\n",
    "dsm[18][24] = 1\n",
    "dsm[18][27] = 1\n",
    "dsm[18][28] = 1\n",
    "dsm[18][29] = 1\n",
    "\n",
    "dsm[19][24] = 1\n",
    "dsm[19][27] = 1\n",
    "dsm[19][36] = 1\n",
    "\n",
    "dsm[20][24] = 1\n",
    "dsm[20][25] = 1\n",
    "dsm[20][27] = 1\n",
    "dsm[20][36] = 1\n",
    "dsm[20][37] = 1\n",
    "\n",
    "dsm[21][31] = 1\n",
    "\n",
    "dsm[22][23] = 1\n",
    "dsm[22][27] = 1\n",
    "dsm[22][28] = 1\n",
    "dsm[22][29] = 1\n",
    "dsm[22][37] = 1\n",
    "\n",
    "dsm[23][31] = 1\n",
    "dsm[23][37] = 1\n",
    "\n",
    "dsm[24][25] = 1\n",
    "dsm[24][27] = 1\n",
    "dsm[24][28] = 1\n",
    "dsm[24][29] = 1\n",
    "dsm[24][37] = 1\n",
    "\n",
    "dsm[25][27] = 1\n",
    "dsm[25][36] = 1\n",
    "dsm[25][37] = 1\n",
    "\n",
    "dsm[26][27] = 1\n",
    "dsm[26][29] = 1\n",
    "\n",
    "dsm[27][28] = 1\n",
    "dsm[27][29] = 1\n",
    "dsm[27][37] = 1\n",
    "\n",
    "dsm[28][29] = 1\n",
    "dsm[28][37] = 1\n",
    "\n",
    "dsm[29][33] = 1\n",
    "dsm[29][34] = 1\n",
    "\n",
    "dsm[30][31] = 1\n",
    "dsm[30][32] = 1\n",
    "\n",
    "dsm[31][32] = 1\n",
    "\n",
    "# make dsm symmetric\n",
    "for i in range(len(dsm)):\n",
    "    for j in range(len(dsm[0])):\n",
    "        if dsm[i][j] == 1:\n",
    "            dsm[j][i] == 1\n",
    "\n",
    "node_feat_matrix = np.random.random((n, n_nf))\n",
    "\n",
    "graphs.append(dsm)\n",
    "node_features.append(node_feat_matrix)\n",
    "\n",
    "labels.append(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the dsm1\n",
    "dsm1 = np.identity(n)\n",
    "\n",
    "dsm1[0][2] = 1\n",
    "dsm1[0][3] = 1\n",
    "dsm1[0][7] = 1\n",
    "dsm1[0][10] = 1\n",
    "dsm1[0][32] = 1\n",
    "dsm1[0][35] = 1\n",
    "\n",
    "dsm1[1][7] = 1\n",
    "dsm1[1][8] = 1\n",
    "dsm1[1][32] = 1\n",
    "\n",
    "dsm1[2][10] = 1\n",
    "dsm1[2][13] = 1\n",
    "dsm1[2][14] = 1\n",
    "dsm1[2][29] = 1\n",
    "dsm1[2][35] = 1\n",
    "\n",
    "dsm1[3][7] = 1\n",
    "dsm1[3][13] = 1\n",
    "dsm1[3][29] = 1\n",
    "dsm1[3][35] = 1\n",
    "\n",
    "dsm1[4][5] = 1\n",
    "dsm1[4][6] = 1\n",
    "dsm1[4][20] = 1\n",
    "dsm1[4][25] = 1\n",
    "dsm1[4][36] = 1\n",
    "\n",
    "dsm1[5][6] = 1\n",
    "dsm1[5][20] = 1\n",
    "\n",
    "dsm1[6][20] = 1\n",
    "dsm1[6][22] = 1\n",
    "dsm1[6][23] = 1\n",
    "dsm1[6][37] = 1\n",
    "\n",
    "dsm1[7][8] = 1\n",
    "dsm1[7][14] = 1\n",
    "dsm1[7][22] = 1\n",
    "dsm1[7][23] = 1\n",
    "dsm1[7][28] = 1\n",
    "dsm1[7][29] = 1\n",
    "dsm1[7][30] = 1\n",
    "dsm1[7][31] = 1\n",
    "dsm1[7][32] = 1\n",
    "dsm1[7][33] = 1\n",
    "dsm1[7][34] = 1\n",
    "\n",
    "dsm1[8][28] = 1\n",
    "dsm1[8][29] = 1\n",
    "\n",
    "dsm1[9][12] = 1\n",
    "dsm1[9][13] = 1\n",
    "dsm1[9][18] = 1\n",
    "dsm1[9][33] = 1\n",
    "dsm1[9][34] = 1\n",
    "\n",
    "dsm1[10][13] = 1\n",
    "dsm1[10][17] = 1\n",
    "dsm1[10][35] = 1\n",
    "\n",
    "dsm1[11][19] = 1\n",
    "dsm1[11][27] = 1\n",
    "dsm1[11][36] = 1\n",
    "\n",
    "dsm1[12][13] = 1\n",
    "\n",
    "dsm1[13][14] = 1\n",
    "dsm1[13][16] = 1\n",
    "dsm1[13][17] = 1\n",
    "\n",
    "dsm1[14][16] = 1\n",
    "dsm1[14][18] = 1\n",
    "dsm1[14][26] = 1\n",
    "dsm1[14][27] = 1\n",
    "dsm1[14][29] = 1\n",
    "\n",
    "dsm1[15][31] = 1\n",
    "dsm1[15][32] = 1\n",
    "\n",
    "dsm1[16][17] = 1\n",
    "dsm1[16][26] = 1\n",
    "\n",
    "dsm1[17][35] = 1\n",
    "\n",
    "dsm1[18][19] = 1\n",
    "dsm1[18][24] = 1\n",
    "dsm1[18][27] = 1\n",
    "dsm1[18][28] = 1\n",
    "dsm1[18][29] = 1\n",
    "\n",
    "dsm1[19][24] = 1\n",
    "dsm1[19][27] = 1\n",
    "dsm1[19][36] = 1\n",
    "\n",
    "dsm1[20][24] = 1\n",
    "dsm1[20][25] = 1\n",
    "dsm1[20][27] = 1\n",
    "dsm1[20][36] = 1\n",
    "dsm1[20][37] = 1\n",
    "\n",
    "dsm1[21][31] = 1\n",
    "\n",
    "dsm1[22][23] = 1\n",
    "dsm1[22][27] = 1\n",
    "dsm1[22][28] = 1\n",
    "dsm1[22][29] = 1\n",
    "dsm1[22][37] = 1\n",
    "\n",
    "dsm1[23][31] = 1\n",
    "dsm1[23][37] = 1\n",
    "\n",
    "dsm1[24][25] = 1\n",
    "dsm1[24][27] = 1\n",
    "dsm1[24][28] = 1\n",
    "dsm1[24][29] = 1\n",
    "dsm1[24][37] = 1\n",
    "\n",
    "dsm1[25][27] = 1\n",
    "dsm1[25][36] = 1\n",
    "dsm1[25][37] = 1\n",
    "\n",
    "dsm1[26][27] = 1\n",
    "dsm1[26][29] = 1\n",
    "\n",
    "dsm1[27][28] = 1\n",
    "dsm1[27][29] = 1\n",
    "dsm1[27][37] = 1\n",
    "\n",
    "dsm1[28][29] = 1\n",
    "dsm1[28][37] = 1\n",
    "\n",
    "dsm1[29][33] = 1\n",
    "dsm1[29][34] = 1\n",
    "\n",
    "dsm1[30][31] = 1\n",
    "dsm1[30][32] = 1\n",
    "\n",
    "dsm1[31][32] = 1\n",
    "\n",
    "# new\n",
    "dsm1[2][4] = 1\n",
    "\n",
    "# make dsm symmetric\n",
    "for i in range(len(dsm1)):\n",
    "    for j in range(len(dsm1[0])):\n",
    "        if dsm1[i][j] == 1:\n",
    "            dsm1[j][i] == 1\n",
    "\n",
    "node_feat_matrix = np.random.random((n, n_nf))\n",
    "\n",
    "graphs.append(dsm1)\n",
    "node_features.append(node_feat_matrix)\n",
    "\n",
    "labels.append(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the dsm1\n",
    "dsm2 = np.identity(n)\n",
    "\n",
    "dsm2[0][2] = 1\n",
    "dsm2[0][3] = 1\n",
    "dsm2[0][7] = 1\n",
    "dsm2[0][10] = 1\n",
    "dsm2[0][32] = 1\n",
    "dsm2[0][35] = 1\n",
    "\n",
    "dsm2[1][7] = 1\n",
    "dsm2[1][8] = 1\n",
    "dsm2[1][32] = 1\n",
    "\n",
    "dsm2[2][10] = 1\n",
    "dsm2[2][13] = 1\n",
    "dsm2[2][14] = 1\n",
    "dsm2[2][29] = 1\n",
    "dsm2[2][35] = 1\n",
    "\n",
    "dsm2[3][7] = 1\n",
    "dsm2[3][13] = 1\n",
    "dsm2[3][29] = 1\n",
    "dsm2[3][35] = 1\n",
    "\n",
    "dsm2[4][5] = 1\n",
    "dsm2[4][6] = 1\n",
    "dsm2[4][20] = 1\n",
    "dsm2[4][25] = 1\n",
    "dsm2[4][36] = 1\n",
    "\n",
    "dsm2[5][6] = 1\n",
    "dsm2[5][20] = 1\n",
    "\n",
    "dsm2[6][20] = 1\n",
    "dsm2[6][22] = 1\n",
    "dsm2[6][23] = 1\n",
    "dsm2[6][37] = 1\n",
    "\n",
    "dsm2[7][8] = 1\n",
    "dsm2[7][14] = 1\n",
    "dsm2[7][22] = 1\n",
    "dsm2[7][23] = 1\n",
    "dsm2[7][28] = 1\n",
    "dsm2[7][29] = 1\n",
    "dsm2[7][30] = 1\n",
    "dsm2[7][31] = 1\n",
    "dsm2[7][32] = 1\n",
    "dsm2[7][33] = 1\n",
    "dsm2[7][34] = 1\n",
    "\n",
    "dsm2[8][28] = 1\n",
    "dsm2[8][29] = 1\n",
    "\n",
    "dsm2[9][12] = 1\n",
    "dsm2[9][13] = 1\n",
    "dsm2[9][18] = 1\n",
    "dsm2[9][33] = 1\n",
    "dsm2[9][34] = 1\n",
    "\n",
    "dsm2[10][13] = 1\n",
    "dsm2[10][17] = 1\n",
    "dsm2[10][35] = 1\n",
    "\n",
    "dsm2[11][19] = 1\n",
    "dsm2[11][27] = 1\n",
    "dsm2[11][36] = 1\n",
    "\n",
    "dsm2[12][13] = 1\n",
    "\n",
    "dsm2[13][14] = 1\n",
    "dsm2[13][16] = 1\n",
    "dsm2[13][17] = 1\n",
    "\n",
    "dsm2[14][16] = 1\n",
    "dsm2[14][18] = 1\n",
    "dsm2[14][26] = 1\n",
    "dsm2[14][27] = 1\n",
    "dsm2[14][29] = 1\n",
    "\n",
    "dsm2[15][31] = 1\n",
    "dsm2[15][32] = 1\n",
    "dsm2[16][17] = 1\n",
    "dsm2[16][26] = 1\n",
    "\n",
    "dsm2[17][35] = 1\n",
    "\n",
    "dsm2[18][19] = 1\n",
    "dsm2[18][24] = 1\n",
    "dsm2[18][27] = 1\n",
    "dsm2[18][28] = 1\n",
    "dsm2[18][29] = 1\n",
    "\n",
    "dsm2[19][24] = 1\n",
    "dsm2[19][27] = 1\n",
    "dsm2[19][36] = 1\n",
    "\n",
    "dsm2[20][24] = 1\n",
    "dsm2[20][25] = 1\n",
    "dsm2[20][27] = 1\n",
    "dsm2[20][36] = 1\n",
    "dsm2[20][37] = 1\n",
    "\n",
    "dsm2[21][31] = 1\n",
    "\n",
    "dsm2[22][23] = 1\n",
    "dsm2[22][27] = 1\n",
    "dsm2[22][28] = 1\n",
    "dsm2[22][29] = 1\n",
    "dsm2[22][37] = 1\n",
    "\n",
    "dsm2[23][31] = 1\n",
    "dsm2[23][37] = 1\n",
    "\n",
    "dsm2[24][25] = 1\n",
    "dsm2[24][27] = 1\n",
    "dsm2[24][28] = 1\n",
    "dsm2[24][29] = 1\n",
    "dsm2[24][37] = 1\n",
    "\n",
    "dsm2[25][27] = 1\n",
    "dsm2[25][36] = 1\n",
    "dsm2[25][37] = 1\n",
    "\n",
    "dsm2[26][27] = 1\n",
    "dsm2[26][29] = 1\n",
    "\n",
    "dsm2[27][28] = 1\n",
    "dsm2[27][29] = 1\n",
    "dsm2[27][37] = 1\n",
    "\n",
    "dsm2[28][29] = 1\n",
    "dsm2[28][37] = 1\n",
    "\n",
    "dsm2[29][33] = 1\n",
    "dsm2[29][34] = 1\n",
    "\n",
    "dsm2[30][31] = 1\n",
    "dsm2[30][32] = 1\n",
    "\n",
    "dsm2[31][32] = 1\n",
    "\n",
    "# new\n",
    "dsm2[2][4] = 1\n",
    "dsm2[0][9] = 1\n",
    "\n",
    "# make dsm symmetric\n",
    "for i in range(len(dsm2)):\n",
    "    for j in range(len(dsm2[0])):\n",
    "        if dsm2[i][j] == 1:\n",
    "            dsm2[j][i] == 1\n",
    "\n",
    "node_feat_matrix = np.random.random((n, n_nf))\n",
    "\n",
    "graphs.append(dsm2)\n",
    "node_features.append(node_feat_matrix)\n",
    "\n",
    "labels.append(2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the dsm\n",
    "dsm3 = np.identity(n)\n",
    "\n",
    "dsm3[0][2] = 1\n",
    "dsm3[0][3] = 1\n",
    "dsm3[0][7] = 1\n",
    "dsm3[0][10] = 1\n",
    "dsm3[0][32] = 1\n",
    "dsm3[0][35] = 1\n",
    "\n",
    "dsm3[1][7] = 1\n",
    "dsm3[1][8] = 1\n",
    "dsm3[1][32] = 1\n",
    "\n",
    "dsm3[2][10] = 1\n",
    "dsm3[2][13] = 1\n",
    "dsm3[2][14] = 1\n",
    "dsm3[2][29] = 1\n",
    "dsm3[2][35] = 1\n",
    "\n",
    "dsm3[3][7] = 1\n",
    "dsm3[3][13] = 1\n",
    "dsm3[3][29] = 1\n",
    "dsm3[3][35] = 1\n",
    "\n",
    "dsm3[4][5] = 1\n",
    "dsm3[4][6] = 1\n",
    "dsm3[4][20] = 1\n",
    "dsm3[4][25] = 1\n",
    "dsm3[4][36] = 1\n",
    "\n",
    "dsm3[5][6] = 1\n",
    "dsm3[5][20] = 1\n",
    "\n",
    "dsm3[6][20] = 1\n",
    "dsm3[6][22] = 1\n",
    "dsm3[6][23] = 1\n",
    "dsm3[6][37] = 1\n",
    "\n",
    "dsm3[7][8] = 1\n",
    "dsm3[7][14] = 1\n",
    "dsm3[7][22] = 1\n",
    "dsm3[7][23] = 1\n",
    "dsm3[7][28] = 1\n",
    "dsm3[7][29] = 1\n",
    "dsm3[7][30] = 1\n",
    "dsm3[7][31] = 1\n",
    "dsm3[7][32] = 1\n",
    "dsm3[7][33] = 1\n",
    "dsm3[7][34] = 1\n",
    "\n",
    "dsm3[8][28] = 1\n",
    "dsm3[8][29] = 1\n",
    "\n",
    "dsm3[9][12] = 1\n",
    "dsm3[9][13] = 1\n",
    "dsm3[9][18] = 1\n",
    "dsm3[9][33] = 1\n",
    "dsm3[9][34] = 1\n",
    "\n",
    "dsm3[10][13] = 1\n",
    "dsm3[10][17] = 1\n",
    "dsm3[10][35] = 1\n",
    "\n",
    "dsm3[11][19] = 1\n",
    "dsm3[11][27] = 1\n",
    "dsm3[11][36] = 1\n",
    "\n",
    "dsm3[12][13] = 1\n",
    "\n",
    "dsm3[13][14] = 1\n",
    "dsm3[13][16] = 1\n",
    "dsm3[13][17] = 1\n",
    "\n",
    "dsm3[14][16] = 1\n",
    "dsm3[14][18] = 1\n",
    "dsm3[14][26] = 1\n",
    "dsm3[14][27] = 1\n",
    "dsm3[14][29] = 1\n",
    "\n",
    "dsm3[15][31] = 1\n",
    "dsm3[15][32] = 1\n",
    "\n",
    "dsm3[16][17] = 1\n",
    "dsm3[16][26] = 1\n",
    "\n",
    "dsm3[17][35] = 1\n",
    "\n",
    "dsm3[18][19] = 1\n",
    "dsm3[18][24] = 1\n",
    "dsm3[18][27] = 1\n",
    "dsm3[18][28] = 1\n",
    "dsm3[18][29] = 1\n",
    "\n",
    "dsm3[19][24] = 1\n",
    "dsm3[19][27] = 1\n",
    "dsm3[19][36] = 1\n",
    "\n",
    "dsm3[20][24] = 1\n",
    "dsm3[20][25] = 1\n",
    "dsm3[20][27] = 1\n",
    "dsm3[20][36] = 1\n",
    "dsm3[20][37] = 1\n",
    "\n",
    "dsm3[21][31] = 1\n",
    "\n",
    "dsm3[22][23] = 1\n",
    "dsm3[22][27] = 1\n",
    "dsm3[22][28] = 1\n",
    "dsm3[22][29] = 1\n",
    "dsm3[22][37] = 1\n",
    "\n",
    "dsm3[23][31] = 1\n",
    "dsm3[23][37] = 1\n",
    "\n",
    "dsm3[24][25] = 1\n",
    "dsm3[24][27] = 1\n",
    "dsm3[24][28] = 1\n",
    "dsm3[24][29] = 1\n",
    "dsm3[24][37] = 1\n",
    "\n",
    "dsm3[25][27] = 1\n",
    "dsm3[25][36] = 1\n",
    "dsm3[25][37] = 1\n",
    "\n",
    "dsm3[26][27] = 1\n",
    "dsm3[26][29] = 1\n",
    "\n",
    "dsm3[27][28] = 1\n",
    "dsm3[27][29] = 1\n",
    "dsm3[27][37] = 1\n",
    "\n",
    "dsm3[28][29] = 1\n",
    "dsm3[28][37] = 1\n",
    "\n",
    "dsm3[29][33] = 1\n",
    "dsm3[29][34] = 1\n",
    "\n",
    "dsm3[30][31] = 1\n",
    "dsm3[30][32] = 1\n",
    "\n",
    "dsm3[31][32] = 1\n",
    "\n",
    "# new\n",
    "dsm3[2][4] = 1\n",
    "dsm3[0][9] = 1\n",
    "dsm3[1][21] = 1\n",
    "\n",
    "# make dsm symmetric\n",
    "for i in range(len(dsm3)):\n",
    "    for j in range(len(dsm3[0])):\n",
    "        if dsm3[i][j] == 1:\n",
    "            dsm3[j][i] == 1\n",
    "\n",
    "node_feat_matrix = np.random.random((n, n_nf))\n",
    "\n",
    "graphs.append(dsm3)\n",
    "node_features.append(node_feat_matrix)\n",
    "\n",
    "labels.append(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load graphs into graph object\n",
    "\n",
    "We now have three lists of length 100. The graphs list is composed of numpy arrays that represent the adjacency matrix of the graph. The node features list is composed of numpy arrays that contain the node information for each graph. The labels list is a list of integers that corresponds to the class label for each graph.\n",
    "\n",
    "The next step is to take this data and convert it into an appropriate format for hcga."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting this data into the format required for hcga\n",
    "\n",
    "from hcga.graph import Graph, GraphCollection\n",
    "\n",
    "# create graph collection object\n",
    "g_c = GraphCollection()\n",
    "\n",
    "# add graphs, node features and labels to the object\n",
    "g_c.add_graph_list(graphs, node_features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 4 graphs\n",
      "There are 10 features per node\n"
     ]
    }
   ],
   "source": [
    "# perform some sanity checks\n",
    "\n",
    "print(\"There are {} graphs\".format(len(g_c.graphs)))\n",
    "print(\"There are {} features per node\".format(g_c.get_n_node_features()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can save this if we want to and run everything from the command line\n",
    "from hcga.io import save_dataset\n",
    "\n",
    "save_dataset(\n",
    "    g_c,\n",
    "    \"Body_in_White\",\n",
    "    folder=\"./datasets/BiW_for_clustering\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracting features\n",
    "\n",
    "We have now produced a pickle dataset of your own custom data. We can now run the feature extraction from the command line using the following commands:\n",
    "\n",
    "hcga extract_features ./datasets/custom_dataset.pkl -m fast -n 4 -sl advanced --timeout 10 \n",
    "\n",
    "\n",
    "Alternatively,we could import the Hcga class and run the feature extraction and analysis from within the notebook. We will do this below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import hcga object\n",
    "from hcga.hcga import Hcga\n",
    "\n",
    "# define an object\n",
    "h = Hcga()\n",
    "\n",
    "# load previously saved dataset\n",
    "h.load_data(\n",
    "    \"./datasets/BiW_for_clustering/Body_in_White.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hcga.extraction:Setting up feature classes...\n",
      "100%|██████████| 43/43 [00:05<00:00,  7.84it/s]\n",
      "INFO:hcga.extraction:Extracting features from 4 graphs (we disabled 0 graphs).\n",
      "INFO:hcga.extraction:Computing features for 4 graphs:\n",
      "100%|██████████| 4/4 [02:03<00:00, 30.96s/it]\n",
      "INFO:hcga.extraction:2536 feature extracted.\n"
     ]
    }
   ],
   "source": [
    "# extracting all features here\n",
    "h.extract(mode=\"fast\", n_workers=32, timeout=20)\n",
    "\n",
    "# saving all features into a pickle\n",
    "h.save_features(\"./results/BiW_for_clustering/all_features.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis - classification example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the saved features\n",
    "\n",
    "h.load_features(\"./results/BiW_for_clustering/all_features.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:hcga.analysis:... Using Xgboost classifier ...\n",
      "INFO:hcga.analysis:2536 total features\n",
      "INFO:hcga.analysis:0 graphs were removed for more than 0.3 fraction of bad features\n",
      "INFO:hcga.analysis:2249 valid features\n",
      "INFO:hcga.analysis:2249 with interpretability 1\n",
      "INFO:hcga.analysis:Counts of graphs/label: \n",
      "2.0    2\n",
      "0.0    1\n",
      "1.0    1\n",
      "Name: label, dtype: int64\n",
      "INFO:hcga.analysis:Using 2 splits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1. 2.]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# implement a classification analyse of the features\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m h\u001b[39m.\u001b[39;49manalyse_features(\n\u001b[1;32m      4\u001b[0m     feature_file\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m./results/BiW_for_clustering/all_features.pkl\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      5\u001b[0m     results_folder\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m./results/BiW_for_clustering\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m      6\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hcga/hcga.py:161\u001b[0m, in \u001b[0;36mHcga.analyse_features\u001b[0;34m(self, feature_file, results_folder, graph_removal, interpretability, analysis_type, model, compute_shap, kfold, reduce_set, reduced_set_size, reduced_set_max_correlation, plot, max_feats_plot, max_feats_plot_dendrogram, n_repeats, n_splits, random_state, test_size, trained_model, save_model)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[39mif\u001b[39;00m feature_file \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mload_features(feature_file\u001b[39m=\u001b[39mfeature_file)\n\u001b[0;32m--> 161\u001b[0m analysis(\n\u001b[1;32m    162\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures,\n\u001b[1;32m    163\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfeatures_info,\n\u001b[1;32m    164\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgraphs,\n\u001b[1;32m    165\u001b[0m     analysis_type\u001b[39m=\u001b[39;49manalysis_type,\n\u001b[1;32m    166\u001b[0m     folder\u001b[39m=\u001b[39;49mresults_folder,\n\u001b[1;32m    167\u001b[0m     graph_removal\u001b[39m=\u001b[39;49mgraph_removal,\n\u001b[1;32m    168\u001b[0m     interpretability\u001b[39m=\u001b[39;49minterpretability,\n\u001b[1;32m    169\u001b[0m     model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    170\u001b[0m     compute_shap\u001b[39m=\u001b[39;49mcompute_shap,\n\u001b[1;32m    171\u001b[0m     kfold\u001b[39m=\u001b[39;49mkfold,\n\u001b[1;32m    172\u001b[0m     reduce_set\u001b[39m=\u001b[39;49mreduce_set,\n\u001b[1;32m    173\u001b[0m     reduced_set_size\u001b[39m=\u001b[39;49mreduced_set_size,\n\u001b[1;32m    174\u001b[0m     reduced_set_max_correlation\u001b[39m=\u001b[39;49mreduced_set_max_correlation,\n\u001b[1;32m    175\u001b[0m     plot\u001b[39m=\u001b[39;49mplot,\n\u001b[1;32m    176\u001b[0m     max_feats_plot\u001b[39m=\u001b[39;49mmax_feats_plot,\n\u001b[1;32m    177\u001b[0m     max_feats_plot_dendrogram\u001b[39m=\u001b[39;49mmax_feats_plot_dendrogram,\n\u001b[1;32m    178\u001b[0m     n_repeats\u001b[39m=\u001b[39;49mn_repeats,\n\u001b[1;32m    179\u001b[0m     n_splits\u001b[39m=\u001b[39;49mn_splits,\n\u001b[1;32m    180\u001b[0m     random_state\u001b[39m=\u001b[39;49mrandom_state,\n\u001b[1;32m    181\u001b[0m     test_size\u001b[39m=\u001b[39;49mtest_size,\n\u001b[1;32m    182\u001b[0m     trained_model\u001b[39m=\u001b[39;49mtrained_model,\n\u001b[1;32m    183\u001b[0m     save_model\u001b[39m=\u001b[39;49msave_model,\n\u001b[1;32m    184\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hcga/analysis.py:538\u001b[0m, in \u001b[0;36manalysis\u001b[0;34m(features, features_info, graphs, analysis_type, folder, graph_removal, interpretability, model, compute_shap, kfold, reduce_set, reduced_set_size, reduced_set_max_correlation, plot, max_feats_plot, max_feats_plot_dendrogram, n_repeats, n_splits, random_state, test_size, trained_model, save_model)\u001b[0m\n\u001b[1;32m    535\u001b[0m     \u001b[39mreturn\u001b[39;00m y_predictions\n\u001b[1;32m    537\u001b[0m \u001b[39mif\u001b[39;00m kfold:\n\u001b[0;32m--> 538\u001b[0m     analysis_results \u001b[39m=\u001b[39m fit_model_kfold(\n\u001b[1;32m    539\u001b[0m         features,\n\u001b[1;32m    540\u001b[0m         model,\n\u001b[1;32m    541\u001b[0m         analysis_type\u001b[39m=\u001b[39;49manalysis_type,\n\u001b[1;32m    542\u001b[0m         reduce_set\u001b[39m=\u001b[39;49mreduce_set,\n\u001b[1;32m    543\u001b[0m         reduced_set_size\u001b[39m=\u001b[39;49mreduced_set_size,\n\u001b[1;32m    544\u001b[0m         reduced_set_max_correlation\u001b[39m=\u001b[39;49mreduced_set_max_correlation,\n\u001b[1;32m    545\u001b[0m         n_repeats\u001b[39m=\u001b[39;49mn_repeats,\n\u001b[1;32m    546\u001b[0m         random_state\u001b[39m=\u001b[39;49mrandom_state,\n\u001b[1;32m    547\u001b[0m         n_splits\u001b[39m=\u001b[39;49mn_splits,\n\u001b[1;32m    548\u001b[0m         compute_shap\u001b[39m=\u001b[39;49mcompute_shap,\n\u001b[1;32m    549\u001b[0m     )\n\u001b[1;32m    550\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    551\u001b[0m     analysis_results \u001b[39m=\u001b[39m fit_model(\n\u001b[1;32m    552\u001b[0m         features,\n\u001b[1;32m    553\u001b[0m         model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    560\u001b[0m         compute_shap\u001b[39m=\u001b[39mcompute_shap,\n\u001b[1;32m    561\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hcga/analysis.py:260\u001b[0m, in \u001b[0;36mfit_model_kfold\u001b[0;34m(features, model, analysis_type, reduce_set, reduced_set_size, reduced_set_max_correlation, n_repeats, random_state, n_splits, compute_shap)\u001b[0m\n\u001b[1;32m    257\u001b[0m     L\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mUsing \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m splits\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mstr\u001b[39m(n_splits))\n\u001b[1;32m    258\u001b[0m     folds \u001b[39m=\u001b[39m RepeatedKFold(n_splits\u001b[39m=\u001b[39mn_splits, n_repeats\u001b[39m=\u001b[39mn_repeats, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m--> 260\u001b[0m acc_scores, shap_values \u001b[39m=\u001b[39m _evaluate_kfold(X, y, model, folds, analysis_type, compute_shap)\n\u001b[1;32m    261\u001b[0m _print_accuracy(acc_scores, analysis_type)\n\u001b[1;32m    263\u001b[0m \u001b[39mif\u001b[39;00m compute_shap:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hcga/analysis.py:205\u001b[0m, in \u001b[0;36m_evaluate_kfold\u001b[0;34m(X, y, model, folds, analysis_type, compute_shap)\u001b[0m\n\u001b[1;32m    203\u001b[0m acc_scores \u001b[39m=\u001b[39m []\n\u001b[1;32m    204\u001b[0m \u001b[39mfor\u001b[39;00m indices \u001b[39min\u001b[39;00m folds\u001b[39m.\u001b[39msplit(X, y\u001b[39m=\u001b[39my):\n\u001b[0;32m--> 205\u001b[0m     acc_score, shap_value \u001b[39m=\u001b[39m _compute_fold(X, y, model, indices, analysis_type, compute_shap)\n\u001b[1;32m    206\u001b[0m     shap_values\u001b[39m.\u001b[39mappend(shap_value)\n\u001b[1;32m    207\u001b[0m     acc_scores\u001b[39m.\u001b[39mappend(acc_score)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/hcga/analysis.py:393\u001b[0m, in \u001b[0;36m_compute_fold\u001b[0;34m(X, y, model, indices, analysis_type, compute_shap)\u001b[0m\n\u001b[1;32m    391\u001b[0m \u001b[39m\"\"\"Compute a single fold for parallel computation.\"\"\"\u001b[39;00m\n\u001b[1;32m    392\u001b[0m train_index, val_index \u001b[39m=\u001b[39m indices\n\u001b[0;32m--> 393\u001b[0m model\u001b[39m.\u001b[39;49mfit(X\u001b[39m.\u001b[39;49miloc[train_index], y\u001b[39m.\u001b[39;49miloc[train_index])\n\u001b[1;32m    395\u001b[0m \u001b[39mif\u001b[39;00m analysis_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mclassification\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    396\u001b[0m     acc_score \u001b[39m=\u001b[39m accuracy_score(y\u001b[39m.\u001b[39miloc[val_index], model\u001b[39m.\u001b[39mpredict(X\u001b[39m.\u001b[39miloc[val_index]))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/core.py:620\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[39mfor\u001b[39;00m k, arg \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(sig\u001b[39m.\u001b[39mparameters, args):\n\u001b[1;32m    619\u001b[0m     kwargs[k] \u001b[39m=\u001b[39m arg\n\u001b[0;32m--> 620\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/xgboost/sklearn.py:1466\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights, callbacks)\u001b[0m\n\u001b[1;32m   1461\u001b[0m     expected_classes \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marange(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_classes_)\n\u001b[1;32m   1462\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m   1463\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m.\u001b[39mshape \u001b[39m!=\u001b[39m expected_classes\u001b[39m.\u001b[39mshape\n\u001b[1;32m   1464\u001b[0m     \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_ \u001b[39m==\u001b[39m expected_classes)\u001b[39m.\u001b[39mall()\n\u001b[1;32m   1465\u001b[0m ):\n\u001b[0;32m-> 1466\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1467\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1468\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mExpected: \u001b[39m\u001b[39m{\u001b[39;00mexpected_classes\u001b[39m}\u001b[39;00m\u001b[39m, got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclasses_\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1469\u001b[0m     )\n\u001b[1;32m   1471\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_xgb_params()\n\u001b[1;32m   1473\u001b[0m \u001b[39mif\u001b[39;00m callable(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobjective):\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got [1. 2.]"
     ]
    }
   ],
   "source": [
    "# implement a classification analyse of the features\n",
    "\n",
    "h.analyse_features(\n",
    "    feature_file=\"./results/BiW_for_clustering/all_features.pkl\",\n",
    "    results_folder=\"./results/BiW_for_clustering\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
